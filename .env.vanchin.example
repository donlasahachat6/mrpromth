# Vanchin AI Configuration
# OpenAI-compatible API with 20M free tokens
# No need to set these in .env - they're hardcoded in lib/ai/vanchin-client.ts

# Vanchin AI Base URL
VANCHIN_BASE_URL=https://vanchin.streamlake.ai/api/gateway/v1/endpoints

# Models are configured in lib/ai/vanchin-client.ts
# Total: 19 models available
# Each model has its own API key and endpoint ID

# Usage:
# import { createVanchinClient, getModelEndpoint } from '@/lib/ai/vanchin-client'
# const client = createVanchinClient('model_1')
# const endpoint = getModelEndpoint('model_1')

# Or use load balancing:
# import { getNextModel } from '@/lib/ai/vanchin-client'
# const { client, endpoint } = getNextModel()

# Benefits:
# - 20M free tokens total
# - Automatic load balancing
# - OpenAI-compatible API
# - No API key needed in .env
